version: '3.8'

networks:
  default:
    name: burcin_network
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.32.224/27
          gateway: 192.168.32.225

services:

  minio:
    container_name: minio
    image: minio/minio:latest
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        mkdir -p /data/mimir-blocks && \
        mkdir -p /data/mimir-ruler && \
        mkdir -p /data/mimir-alertmanager && \
        mkdir -p /data/tempo && \
        minio server /data \
        --console-address ':9001'
    environment:
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    ports:
      - 9001:9001
    volumes:
      - ~/.docker/volumes/burcin/minio/data:/data

  promtail:
    container_name: promtail
    image: grafana/promtail:latest
    volumes:
      - ./config/promtail.yml:/etc/promtail/config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yaml

  loki:
    container_name: loki
    image: grafana/loki:latest
    command: "-config.file=/etc/loki/config.yaml"
    ports:
      - 3100:3100
      - 7946
      - 9095
    volumes:
      - ./config/loki.yml:/etc/loki/config.yaml
    depends_on:
      - minio

  tempo:
    container_name: tempo
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./config/tempo.yml:/etc/tempo.yaml
      - ~/.docker/volumes/burcin/tempo:/tmp/tempo
    ports:
      - "3200:3200" # tempo
      - "14268:14268" # jaeger ingest
      - "4317:4317" # otlp grpc
      - "4318:4318" # otlp http
      - "9411:9411" # zipkin
    links:
      - prometheus-server

  mimir-1:
    container_name: mimir-1
    image: grafana/mimir:latest
    command: [ "-config.file=/etc/mimir.yaml" ]
    hostname: mimir-1
    depends_on:
      - minio
    volumes:
      - ./config/mimir.yml:/etc/mimir.yaml
      - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - ~/.docker/volumes/burcin/mimir-1/data:/data
  mimir-2:
    container_name: mimir-2
    image: grafana/mimir:latest
    command: [ "-config.file=/etc/mimir.yaml" ]
    hostname: mimir-2
    depends_on:
      - minio
    volumes:
      - ./config/mimir.yml:/etc/mimir.yaml
      - ./config/alertmanager-fallback-config.yaml:/etc/alertmanager-fallback-config.yaml
      - ~/.docker/volumes/burcin/mimir-2/data:/data

  load-balancer:
    image: nginx:latest
    volumes:
      - ./config/mimir-nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - "mimir-1"
      - "mimir-2"
    ports:
      - 9009:9009

  prometheus-server:
    container_name: prometheus-server
    image: prom/prometheus:v2.44.0
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ~/.docker/volumes/burcin/prometheus:/prometheus
      - ./config/prometheus-rules.yml:/etc/prometheus/rules.yaml
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - "mimir-1"
      - "mimir-2"

  prometheus-pushgateway:
    container_name: prometheus-pushgateway
    image: prom/pushgateway:v1.6.0
    ports:
      - "9091:9091"

  prometheus-alertmanager:
    container_name: prometheus-alertmanager
    image: prom/alertmanager:v0.25.0
    ports:
      - "9093:9093"

  prometheus-node-exporter:
    container_name: prometheus-node-exporter
    image: prom/node-exporter:v1.6.0
    ports:
      - "9100:9100"

  grafana:
    container_name: grafana
    image: grafana/grafana:9.5.3
    environment:
      - GF_INSTALL_PLUGINS=raintank-worldping-app,grafana-azure-data-explorer-datasource,marcusolsson-json-datasource
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    ports:
      - "3000:3000"
    volumes:
      - ./config/grafana-datasources.yml:/etc/grafana/provisioning/datasources/ds.yaml
      - ./config/grafana-dashboard.yml:/etc/grafana/provisioning/dashboards/sy.yaml
      - ./config/dashboards:/var/lib/grafana/dashboards/docker-compose
      - ~/.docker/volumes/burcin/grafana:/var/lib/grafana

  # vault:
  #   container_name: vault
  #   image: vault:1.11.3
  #   environment:
  #     # - VAULT_DEV_ROOT_TOKEN_ID=pass
  #     - VAULT_LOG_LEVEL=info
  #     - SKIP_SETCAP=DISABLE_MEMORY_LOCKING
  #     - 'VAULT_LOCAL_CONFIG={"backend":{"file":{"path":"/vault/file"}},"default_lease_ttl":"168h","max_lease_ttl":"720h","disable_mlock":true,"ui":true, "listener": {"tcp":{"address": "0.0.0.0:8200", "tls_disable": 1}}}'
  #   command: [ 'vault', 'server', '-config=/vault/config' ]
  #   ports:
  #     - "8200:8200"
  #   volumes:
  #     - ~/.docker/volumes/burcin/vault/logs:/vault/logs
  #     - ~/.docker/volumes/burcin/vault/file:/vault/file
  #     - ~/.docker/volumes/burcin/vault/config:/vault/config
  #   # cap_add:
  #   #   - IPC_LOCK

  # redis:
  #   container_name: redis
  #   image: "redis:7.0.11-alpine"
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - ~/.docker/volumes/burcin/redis/data:/data
  #     - ./config/redis.conf:/usr/local/etc/redis/redis.conf
  #   command: ["redis-server", "/usr/local/etc/redis/redis.conf"]

  # redis-insight:
  #   container_name: redis-insight
  #   image: redislabs/redisinsight:latest
  #   ports:
  #     - "16379:8001"
  #   depends_on:
  #     - redis
  #   volumes:
  #     - ~/.docker/volumes/burcin/redis-insight/data:/db

  # rabbitmq:
  #   container_name: rabbitmq
  #   hostname: rabbit-1
  #   image: rabbitmq:3.12.0-management-alpine
  #   environment:
  #     - RABBITMQ_ERLANG_COOKIE=unique-erlang-cookie
  #     - RABBITMQ_DEFAULT_USER=test
  #     - RABBITMQ_DEFAULT_PASS=test
  #     - RABBITMQ_PLUGINS_DIR=/opt/rabbitmq/plugins:/usr/lib/rabbitmq/plugins
  #     # rabbitmqctl add_user test test && rabbitmqctl set_user_tags test administrator && rabbitmqctl set_permissions -p / test ".*" ".*" ".*"
  #   command: bash -c "rabbitmq-plugins list && rabbitmq-plugins enable rabbitmq_shovel rabbitmq_shovel_management rabbitmq_delayed_message_exchange && rabbitmq-server"
  #   ports:
  #     - "5672:5672"
  #     - "15672:15672"
  #   volumes:
  #     - ~/.docker/volumes/burcin/rabbitmq:/var/lib/rabbitmq/mnesia
  #     - ~/.docker/volumes/burcin/rabbitmq-plugins:/usr/lib/rabbitmq/plugins

  # mssql:
  #   container_name: mssql
  #   image: cilerler/mssql-server-linux:2019
  #   ports:
  #     - "11433:1433"
  #   environment:
  #     - ACCEPT_EULA=Y
  #     - MSSQL_PID=Developer
  #     - SSIS_PID=Developer
  #     - SA_PASSWORD=S0m3P@$$w0rd
  #     - MSSQL_AGENT_ENABLED=true
  #     - MSSQL_ENABLE_HADR=0
  #   volumes:
  #     - ~/.docker/volumes/burcin/mssql/data:/var/opt/mssql/data
  #     - ~/.docker/volumes/burcin/mssql/log:/var/opt/mssql/log
    # extra_hosts:
    #   - "azuredb.database.windows.net:172.17.1.17"
    # user: root

  # beatpulse:
  #   container_name: "beatpulse"
  #   image: xabarilcoding/healthchecksui:latest
  #   ports:
  #     - "5000:80"
  #   environment:
  #     - HealthChecksUI:EvaluationTimeInSeconds=60
  #     - HealthChecksUI:MinimumSecondsBetweenFailureNotifications=300
  #     - HealthChecksUI:HealthChecks:0:Name=httpBasic
  #     - HealthChecksUI:HealthChecks:0:Uri=http://localhost:47920/health
  #     - HealthChecksUI:Webhooks:0:Name=Slack
  #     - HealthChecksUI:Webhooks:0:Uri=https://hooks.slack.com/services/{ID}
  #     - HealthChecksUI:Webhooks:0:Payload='{"text":"[[LIVENESS]] is failing with the error message [[FAILURE]]            [[DESCRIPTIONS]]","channel":"#devops-alerts","link_names":1,"username":"DevOps-health-service-bot","icon_emoji":":fire:"}'
  #     - HealthChecksUI:Webhooks:0:RestoredPayload='{"text":"[[LIVENESS]] is recovered. All is up and running","channel":"#devops-alerts","link_names":1,"username":"DevOps-health-service-bot","icon_emoji":":fire_engine:"}'
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.125'
  #         memory: 128M
  #       reservations:
  #         cpus: '0.25'
  #         memory: 256M

  # plantuml:
  #   container_name: plantuml
  #   image: plantuml/plantuml-server:tomcat
  #   ports:
  #     - "8080:8080"

  # seq-ingestion:
  #   container_name: "seq-ingestion"
  #   image: datalust/seq-input-gelf:latest
  #   depends_on:
  #     - seq
  #   ports:
  #     - "12201:12201/udp"
  #   environment:
  #     SEQ_ADDRESS: "http://seq:5341"
  #   restart: unless-stopped

  # seq:
  #   container_name: seq
  #   image: datalust/seq:latest
  #   environment:
  #     - ACCEPT_EULA=Y
  #   volumes:
  #     - ~/.docker/volumes/seq/data:/data
  #   ports:
  #     - "5341:5341"
  #     - "15341:80"

  # mongodb:
  #   container_name: mongodb
  #   image: mongo:4.4.0
  #   environment:
  #     - MONGO_INITDB_ROOT_USERNAME=admin
  #     - MONGO_INITDB_ROOT_PASSWORD=admin
  #     - MONGO_INITDB_DATABASE=burcin
  #   volumes:
  #     - /c/.ignore/volumes/mongo/data/db:/data/db
  #   ports:
  #     - "27017:27017"

  # mongo-express:
  #   image: mongo-express:latest
  #   environment:
  #     - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
  #     - ME_CONFIG_MONGODB_ADMINPASSWORD=admin
  #     - ME_CONFIG_MONGODB_SERVER=mongodb
  #   ports:
  #     - "8081:8081"
  #   links:
  #     - mongodb

  # postgresql:
  #   container_name: postgres
  #   image: postgres:12.2-alpine
  #   ports:
  #     - "5432:5432"
  #   # volumes:
  #   #   - /c/.ignore/volumes/postgresql/data:/var/lib/postgresql/data
  #   environment:
  #     - POSTGRES_USER=admin
  #     - POSTGRES_PASSWORD=S0m3P@$$w0rd

  # pgadmin:
  #   image: dpage/pgadmin4:latest
  #   ports:
  #     - "5050:80"
  #   environment:
  #     - PGADMIN_DEFAULT_EMAIL=admin@pgadmin.local
  #     - PGADMIN_DEFAULT_PASSWORD=S0m3P@$$w0rd
  #   links:
  #     - postgresql

  # mysql:
  #   container_name: mysql
  #   image: mysql:8.0.26
  #   command: --default-authentication-plugin=mysql_native_password
  #   ports:
  #     - "3306:3306"
  #   volumes:
  #       - /c/.ignore/volumes/mysql/:/var/lib/mysql
  #   environment:
  #     - MYSQL_DATABASE=db
  #     - MYSQL_USER=user
  #     - MYSQL_PASSWORD=password
  #     - MYSQL_ROOT_PASSWORD=password

  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.16.2
  #   container_name: elasticsearch
  #   environment:
  #     - discovery.type=single-node
  #     # - node.name=elasticsearch
  #     # - cluster.name=docker-cluster
  #     # - cluster.initial_master_nodes=elasticsearch
  #     # - bootstrap.memory_lock=true
  #     # - 'ES_JAVA_OPTS=-Xms1024M -Xmx1024M'
  #     # - http.cors.enabled=true
  #     # - http.cors.allow-origin=*
  #     # - network.host=_eth0_
  #   # ulimits:
  #   #   nproc: 65535
  #   #   memlock:
  #   #     soft: -1
  #   #     hard: -1
  #   # cap_add:
  #   #   - ALL
  #   # privileged: true
  #   # volumes:
  #   #   - 'elastic_data:/usr/share/elasticsearch/data'
  #   ports:
  #     - 9200:9200
  #     - 9300:9300

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:7.16.2
  #   container_name: kibana
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #   ports:
  #     - "5601:5601"
  #   # volumes:
  #   #   - ./kibana.yml:/usr/share/kibana/config/kibana.yml

  # burcin:
  #   container_name: burcin
  #   image: burcin-app
  #   build:
  #     context: ../burcin
  #     dockerfile: ./src/Burcin.Host/Dockerfile
  #     args:
  #       - BUILD_CONFIGURATION=Debug
  #       - GITHUB_PAT=${GITHUB_PAT}
  #   env_file:
  #     - .env
  #     - ./vault/burcin/.env
  #   environment:
  #     - ASPNETCORE_ENVIRONMENT=Development
  #     - ASPNETCORE_URLS=https://+:443;http://+:80
  #     - ASPNETCORE_Kestrel__Certificates__Default__Password=${DEV_CERTS_PASSWORD}
  #     - ASPNETCORE_Kestrel__Certificates__Default__Path=/https/aspnetapp.pfx
  #     - Logging__Console__FormatterName=json
  #     - Logging__Console__FormatterOptions__IncludeScopes=true
  #     - Logging__Console__FormatterOptions__UseUtcTimestamp=false
  #     - Logging__Console__FormatterOptions__TimestampFormat=yyyyMMddHHmmss
  #     - Logging__Console__FormatterOptions__JsonWriterOptions__Indented=false
  #     - PrometheusExporterHttpListener=http://+:80/
  #   ports:
  #     - "5000:80"
  #     - "5001:443"
  #   volumes:
  #     - ${APPDATA}/Microsoft/UserSecrets/Burcin.Host:/root/.microsoft/usersecrets/Burcin.Host:ro
  #     - ~/.aspnet/https:/https:ro
  #   depends_on:
  #     - mssql
  #     - redis
  #   logging:
  #     driver: "gelf"
  #     options:
  #       gelf-address: "udp://host.docker.internal:12201"
  #       # tag: "first-logs"
  #       # max-size: "200k"
  #       # max-file: "10"
  #       # deploy:
  #       #   resources:
  #       #     limits:
  #       #       cpus: '0.25'
  #       #       memory: 256M
  #       #     reservations:
  #       #       cpus: '0.125'
  #       #       memory: 128M

